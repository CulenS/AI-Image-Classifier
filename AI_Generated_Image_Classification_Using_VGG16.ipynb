{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Creating a train and test dataset from the CIFAKE dataset.","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport shutil\n\n# Set the paths to your dataset folders\ndataset_dir = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/train\"\nreal_dir = os.path.join(dataset_dir, \"REAL\")\nfake_dir = os.path.join(dataset_dir, \"FAKE\")\n\n# Set the paths to the new directories that will contain the selected images\ntrain_dir = \"/kaggle/working/train\"\nreal_train_dir = os.path.join(train_dir, \"REAL\")\nfake_train_dir = os.path.join(train_dir, \"FAKE\")\n\n# Create the new directories if they don't exist\nif not os.path.exists(real_train_dir):\n    os.makedirs(real_train_dir)\nif not os.path.exists(fake_train_dir):\n    os.makedirs(fake_train_dir)\n\n# Set the number of images to select from each folder\nnum_images = 2000\n\n# Randomly select the required number of images from the REAL folder and copy them to the new directory\nreal_images = os.listdir(real_dir)\nselected_real_images = random.sample(real_images, num_images)\nfor image_name in selected_real_images:\n    source_path = os.path.join(real_dir, image_name)\n    dest_path = os.path.join(real_train_dir, image_name)\n    shutil.copyfile(source_path, dest_path)\n\n# Randomly select the required number of images from the FAKE folder and copy them to the new directory\nfake_images = os.listdir(fake_dir)\nselected_fake_images = random.sample(fake_images, num_images)\nfor image_name in selected_fake_images:\n    source_path = os.path.join(fake_dir, image_name)\n    dest_path = os.path.join(fake_train_dir, image_name)\n    shutil.copyfile(source_path, dest_path)\n    \n# Set the paths to your dataset folders\ndataset_dir_test = \"/kaggle/input/cifake-real-and-ai-generated-synthetic-images/test\"\nreal_dir = os.path.join(dataset_dir_test, \"REAL\")\nfake_dir = os.path.join(dataset_dir_test, \"FAKE\")\n# Set the paths to the new directories that will contain the selected images\ntest_dir = \"/kaggle/working/test\"\nreal_test_dir = os.path.join(test_dir, \"REAL\")\nfake_test_dir = os.path.join(test_dir, \"FAKE\")\n\n# Create the new directories if they don't exist\nif not os.path.exists(real_test_dir):\n    os.makedirs(real_test_dir)\nif not os.path.exists(fake_test_dir):\n    os.makedirs(fake_test_dir)\n\n# Set the number of images to select from each folder\nnum_images = 200\n\n# Randomly select the required number of images from the REAL folder and copy them to the new directory\nreal_images = os.listdir(real_dir)\nselected_real_images = random.sample(real_images, num_images)\nfor image_name in selected_real_images:\n    source_path = os.path.join(real_dir, image_name)\n    dest_path = os.path.join(real_test_dir, image_name)\n    shutil.copyfile(source_path, dest_path)\n\n# Randomly select the required number of images from the FAKE folder and copy them to the new directory\nfake_images = os.listdir(fake_dir)\nselected_fake_images = random.sample(fake_images, num_images)\nfor image_name in selected_fake_images:\n    source_path = os.path.join(fake_dir, image_name)\n    dest_path = os.path.join(fake_test_dir, image_name)\n    shutil.copyfile(source_path, dest_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T15:12:42.065438Z","iopub.execute_input":"2023-05-16T15:12:42.065862Z","iopub.status.idle":"2023-05-16T15:13:16.830061Z","shell.execute_reply.started":"2023-05-16T15:12:42.065826Z","shell.execute_reply":"2023-05-16T15:13:16.828828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model creation and Evaluation","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport os\nimport cv2\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import average_precision_score\nimport matplotlib.pyplot as plt\n\n\n# Set the paths to the train and test directories\ntrain_dir = '/kaggle/working/train'\ntest_dir = '/kaggle/working/test'\n\n# Set up the model\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nbatch_size=32\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Perform data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n\n# Load the training data\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(32,32),\n                                                    batch_size=batch_size, class_mode='binary')\n\n# Train the model\nhistory = model.fit(train_generator, steps_per_epoch=train_generator.n // batch_size, epochs=50)\n\n# Load the test data\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size=(32,32),\n                                                  batch_size=batch_size, class_mode='binary', shuffle=False)\n\n# Make predictions on the test data\npredictions = model.predict(test_generator)\nlabels = [0 if pred < 0.5 else 1 for pred in predictions]\n\n# Calculate accuracy\naccuracy = np.sum(np.array(test_generator.labels) == np.array(labels)) / len(labels)\n\n# Print the accuracy\nprint(\"\\nAccuracy:\", accuracy)\n\ncm = confusion_matrix(test_generator.labels, labels)\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Compute the classification report\nclass_names = test_generator.class_indices.keys()\nclassification_rep = classification_report(test_generator.labels, labels, target_names=class_names)\nprint(\"\\nClassification Report:\")\nprint(classification_rep)\n\n# Calculate the average precision (mAP)\nmAP = average_precision_score(test_generator.labels, predictions)\nprint(\"\\nMean Average Precision (mAP):\", mAP)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T15:13:25.314426Z","iopub.execute_input":"2023-05-16T15:13:25.314844Z","iopub.status.idle":"2023-05-16T15:44:30.735238Z","shell.execute_reply.started":"2023-05-16T15:13:25.314811Z","shell.execute_reply":"2023-05-16T15:44:30.733811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Result Visualisation**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n# Confusion matrix\ncm = confusion_matrix(test_generator.labels, labels)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Loss plot\nplt.figure(figsize=(8, 6))\nplt.plot(history.history['loss'], label='Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T15:45:44.17792Z","iopub.execute_input":"2023-05-16T15:45:44.178438Z","iopub.status.idle":"2023-05-16T15:45:44.737452Z","shell.execute_reply.started":"2023-05-16T15:45:44.178397Z","shell.execute_reply":"2023-05-16T15:45:44.736176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\n# Calculate precision and recall\nprecision, recall, _ = precision_recall_curve(test_generator.labels, predictions)\n\n# Plot precision-recall curve\nplt.plot(recall, precision)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.grid(True)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:19:33.95769Z","iopub.execute_input":"2023-05-16T16:19:33.958447Z","iopub.status.idle":"2023-05-16T16:19:34.215466Z","shell.execute_reply.started":"2023-05-16T16:19:33.958388Z","shell.execute_reply":"2023-05-16T16:19:34.214136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_curve, auc\n\n# Calculate precision, recall, and thresholds\nprecision, recall, thresholds = precision_recall_curve(test_generator.labels, predictions)\n\n# Calculate F1-score\nf1_scores = 2 * (precision * recall) / (precision + recall)\n\n# Calculate area under the curve (AUC)\nauc_score = auc(recall, precision)\n\n# Plot the F1 curve\nplt.plot(recall, precision, label='F1 curve (AUC = {:.2f})'.format(auc_score))\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('F1 Curve')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:32:29.832129Z","iopub.execute_input":"2023-05-16T16:32:29.832645Z","iopub.status.idle":"2023-05-16T16:32:30.115146Z","shell.execute_reply.started":"2023-05-16T16:32:29.832603Z","shell.execute_reply":"2023-05-16T16:32:30.113531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Confusion matrix\ncm = confusion_matrix(test_generator.labels, labels)\ncm_percent = cm / cm.sum(axis=1).reshape(-1, 1) * 100\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_percent, annot=True, cmap='Blues', fmt='.1f', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:13:02.826061Z","iopub.execute_input":"2023-05-16T16:13:02.827358Z","iopub.status.idle":"2023-05-16T16:13:03.143433Z","shell.execute_reply.started":"2023-05-16T16:13:02.827304Z","shell.execute_reply":"2023-05-16T16:13:03.142121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Select random samples from the test data\nsample_indices = np.random.choice(len(test_generator), size=10, replace=False)\nsample_images = []\nsample_actual_labels = []\nsample_predicted_labels = []\nsample_probabilities = []\n\nfor i in sample_indices:\n    image, actual_labels = test_generator[i]\n    predicted_label = labels[i]\n    probability = predictions[i][0]\n    sample_images.append(image[0])  # Access the first image in the batch\n    sample_actual_labels.append(actual_labels[0])  # Access the actual label for the first image\n    sample_predicted_labels.append(predicted_label)\n    sample_probabilities.append(probability)\n\n# Calculate the subplot layout based on the number of sample images\nnum_images = len(sample_images)\nnum_rows = int(np.ceil(num_images / 2))\nnum_cols = min(num_images, 2)\n\n# Plot the sample images with labels and probabilities\nplt.figure(figsize=(12, 6))\nfor i in range(len(sample_images)):\n    plt.subplot(num_rows, num_cols, i+1)\n    plt.imshow(sample_images[i])\n    actual_label = \"FAKE\" if sample_actual_labels[i] == 0 else \"REAL\"\n    predicted_label = \"FAKE\" if sample_predicted_labels[i] == 0 else \"REAL\"\n    plt.title(f\"Actual: {actual_label}, Predicted: {predicted_label}\\nProbability: {sample_probabilities[i]:.2f}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T16:08:49.441728Z","iopub.execute_input":"2023-05-16T16:08:49.442205Z","iopub.status.idle":"2023-05-16T16:08:50.78254Z","shell.execute_reply.started":"2023-05-16T16:08:49.442166Z","shell.execute_reply":"2023-05-16T16:08:50.781236Z"},"trusted":true},"execution_count":null,"outputs":[]}]}